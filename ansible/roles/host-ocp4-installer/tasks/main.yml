- name: Install client and OpenShift Installer binaries
  import_tasks: install_installer.yml

- name: Generate install_config.yaml
  import_tasks: generate_install_config.yml

# For Windows Nodes OVN is required.
# For 4.6 this requires an install workaround to generate
# manifests and then change the manifests
# For SDN this is not necessary. Regardless the installation will either generate
# manifests if there aren't any (default) or use the updated ones (OVN)
- name: Generate and patch Manifests for OVN
  when: ocp4_network_ovn_install_workaround | default(false) | bool
  block:
  - name: Run Installer to generate manifests
    become: no
    tags:
    - run_installer
    command: openshift-install create manifests --dir=/home/{{ ansible_user }}/{{ cluster_name }}

  - name: Create install workaround manifests/cluster-network-03-config.yml for OVN
    copy:
      src: ./files/cluster-network-03-config.yml
      dest: "/home/{{ ansible_user }}/{{ cluster_name }}/manifests/cluster-network-03-config.yml"
      owner: "{{ ansible_user }}"
      mode: 0660

- name: Installation and getting the logs
  block:
  - name: Run the installer
    become: no
    tags:
    - run_installer
    command: openshift-install create cluster --dir=/home/{{ ansible_user }}/{{ cluster_name }}
    async: "{{ 2 * 60 * 60 }}"
    ignore_errors: yes
  - name: Retry OpenShift installation (wait-for install-complete)
    command: openshift-install --dir=/home/{{ ansible_user }}/{{ cluster_name }} wait-for install-complete

  rescue:
  - name: Restart OpenStack nodes
    when: cloud_provider == "osp"
    block:
    - name: Set Ansible Python interpreter to virtualenv
      set_fact:
        ansible_python_interpreter: "/opt/virtualenvs/k8s/bin/python"

    - name: Get all OpenShift master nodes
      k8s_info:
        kubeconfig: "/home/{{ ansible_user }}/cluster-{{ guid }}/auth/kubeconfig"
        api_version: v1
        kind: Node
        label_selectors:
        - node-role.kubernetes.io/master=
      register: r_nodes

    - name: Set master 0 status
      set_fact:
        __master_status_0: >-
          {{ r_nodes.resources[0] | to_json | from_json
            | json_query("status.conditions[?contains(type,'Ready')].status") | first }}
    - name: Set master 1 status
      set_fact:
        __master_status_1: >-
          {{ r_nodes.resources[1] | to_json | from_json
            | json_query("status.conditions[?contains(type,'Ready')].status") | first }}
    - name: Set master 2 status
      set_fact:
        __master_status_2: >-
          {{ r_nodes.resources[2] | to_json | from_json
            | json_query("status.conditions[?contains(type,'Ready')].status") | first }}

    - name: Debug
      debug:
        msg: "{{ item }}"
      loop:
      - "{{ r_nodes.resources[0].metadata.name }} status: {{ __master_status_0 }}"
      - "{{ r_nodes.resources[1].metadata.name }} status: {{ __master_status_1 }}"
      - "{{ r_nodes.resources[2].metadata.name }} status: {{ __master_status_2 }}"

    - name: Reboot master nodes if NotReady
      when: __master_status_0 is not match("True") or __master_status_1 is not match("True") or __master_status_2 is not match("True")
      block:
      - name: Restart master 0
        when: __master_status_0 is not match("True")
        block:
        - name: Stop master 0
          os_server_action:
            action: stop
            server: "{{ r_nodes.resources[0].metadata.name }}"
            wait: true
        - name: Start Master 0
          os_server_action:
            action: start
            server: "{{ r_nodes.resources[0].metadata.name }}"
            wait: true
      - name: Restart master 1
        when: __master_status_1 is not match("True")
        block:
        - name: Stop master 1
          os_server_action:
            action: stop
            server: "{{ r_nodes.resources[1].metadata.name }}"
            wait: true
        - name: Start Masters
          os_server_action:
            action: start
            server: "{{ r_nodes.resources[1].metadata.name }}"
            wait: true
      - name: Restart master 2
        when: __master_status_2 is not match("True")
        block:
        - name: Stop master 2
          os_server_action:
            action: stop
            server: "{{ r_nodes.resources[2].metadata.name }}"
            wait: true
        - name: Start Master 2
          os_server_action:
            action: start
            server: "{{ r_nodes.resources[2].metadata.name }}"
            wait: true

  - name: Retry OpenShift installation (wait-for bootstrap-complete)
    command: openshift-install --dir=/home/{{ ansible_user }}/{{ cluster_name }} wait-for bootstrap-complete
  - name: Retry OpenShift installation (wait-for install-complete)
    command: openshift-install --dir=/home/{{ ansible_user }}/{{ cluster_name }} wait-for install-complete

  always:
  - name: Gzip Install log
    archive:
      path: /home/{{ ansible_user }}/{{ cluster_name }}/.openshift_install.log
      dest: /home/{{ ansible_user }}/{{ cluster_name }}/.openshift_install.log.gz
      format: gz

  - name: Get Install log
    fetch:
      src: /home/{{ ansible_user }}/{{ cluster_name }}/.openshift_install.log.gz
      dest: "{{ output_dir }}/{{ env_type }}_{{ guid }}_log/"
      flat: yes

# OpenStack does not have a way to add userTags via the install-config.yaml
# https://bugzilla.redhat.com/show_bug.cgi?id=1868517
# Find all created active instances (name contains the GUID)
# and add the tags manually
# Tags are necessary for lifecycle (stop / start environments)
- name: Add tags to OpenStack instance metadata
  when: cloud_provider == "osp"
  block:
  - name: Get all instances for GUID
    os_server_info:
      server: "*{{ guid }}*"
      filters:
        vm_state: active
    register: r_servers

  - name: Add GUID and env-type metadata to instances
    os_server_metadata:
      server: "{{ item.name }}"
      meta:
        guid: "{{ guid }}"
        env_type: "{{ env_type }}"
    loop: "{{ r_servers.openstack_servers }}"

  - name: Add additional metadata to instances
    when: hostvars.localhost.cf_tags_final | default({}) | length > 0
    os_server_metadata:
      server: "{{ item.name }}"
      meta: "{{ hostvars.localhost.cf_tags_final | default({}) | to_json }}"
    loop: "{{ r_servers.openstack_servers }}"

- name: Fetch kube config
  fetch:
    flat: yes
    src: /home/{{ ansible_user }}/{{ cluster_name }}/auth/{{ item }}
    dest: "{{ hostvars.localhost.output_dir }}/{{ env_type }}_{{ guid }}_{{ item }}"
  loop:
  - kubeconfig
  - kubeadmin-password

- name: Make sure .kube directory exists in home directory
  file:
    state: directory
    path: "/home/{{ ansible_user }}/.kube"
    owner: "{{ ansible_user }}"
    mode: 0775

- name: Set up .kube/config
  copy:
    remote_src: yes
    src: "/home/{{ ansible_user }}/{{ cluster_name }}/auth/kubeconfig"
    dest: "/home/{{ ansible_user }}/.kube/config"

- name: Make sure .kube directory exists in /root
  become: yes
  file:
    state: directory
    path: /root/.kube
    owner: root
    mode: 0700

- name: Set up .kube/config for root
  become: yes
  copy:
    remote_src: yes
    src: "/home/{{ ansible_user }}/{{ cluster_name }}/auth/kubeconfig"
    dest: /root/.kube/config

- name: Set up Student User
  when: install_student_user | bool
  block:
  - name: Make sure .kube directory exists in /home/{{ student_name }}
    become: yes
    file:
      state: directory
      path: "/home/{{ student_name }}/.kube"
      owner: "{{ student_name }}"
      mode: 0700

  - name: Copy /home/{{ ansible_user }}/{{ cluster_name }}/auth/kubeconfig to /home/{{ student_name }}/.kube
    become: yes
    copy:
      src: /home/{{ ansible_user }}/{{ cluster_name }}/auth/kubeconfig
      dest: /home/{{ student_name }}/.kube/config
      remote_src: yes
      owner: "{{ student_name }}"
      mode: 0600

- name: Create OpenShift Bash completion file
  become: yes
  shell: oc completion bash >/etc/bash_completion.d/openshift

- name: Gather and Print cluster info
  import_tasks: print_cluster_info.yml

## Open the port for the api
- name: OpenStack specific requirement - attach floating_ip_address to ingress port
  when: cloud_provider == "osp"
  import_tasks: osp_post.yml
